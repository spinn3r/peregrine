

- merger checkpoints must be not only on chunk boundaries but in between keys.

    - if we have keys k1,k1,k1 at the end of chunk0 , and then we transitition
      to chunk1, and it has three keys k1,k1,k1 then we first need to get to the
      end of all three keys before sending off a chunkpoint.  If we didn't do
      this then on resume we would send emit a value of ... FIXME this only
      applies to reduces ... 

- If you assume that every 18 months the computational complexity the process
  speed doubles. ... or the same thing for 1/2 the prices.  If the price of SSDs
  halves every month.  5-6 years before flash is the prices of HDD... It might
  happen sooner because flash gets more used less HDDs will be made.

  

- We should support pluggable checksum algoritihms including Adler32 and CRC32
  (for smaller chunks) and then of course SHA1 if people are paranoid.


- When writing shuffle output to the target partition, we're going to eventually
  have to run a reduce() over that data.  So instead of just writing data the
  order it comes in, allow partitions that are GOING to be reduced in the
  future, to sit next to each other on disk.  This way I can get more throughput
  when I eventually read them.







- we need the ability to split() a map job ... so that it can emit to multiple
  ...  Then we can reduce over these locations.


    mapOuterJoin( mapper, file0, file1, ... , fileN )
    mapInnerJoin( mapper, file0, file1, ... , fileN )
    mapFullOuterJoin( mapper, file0, file1, ... , fileN )

    JoinMapper
    
- The mapGroup and mapOuterJoin are a bit more complicated to handle with
  recovery but not the end of the world.
    
- we probably need to support some sort of inner and outer join syntax for
  previous pagerank iterations:

    http://en.wikipedia.org/wiki/Sort-merge_join


- OK... async IO isn't available right now on JDK 1.6 I think and it isn't SUPER
  clear how to do this with netty... Let netty handle the async IO and then
  write messages to a queue which is drained to disk as a shuffle group by a
  single thread.  There is a single thread per shuffle group writing to disk.
  Creating more than 10 or so isn't really a good idea since a single disk can't
  support this.
    


- the controller should be able to send these messages:

    - json messages should be sent so I can iterate faster and don't need to
      build an encoder/decoder.

        

    - the existing API is becoming a BIT complicated.  One way to simplify it
      would be to serialize messages which we just send from the controller to
      the reducers but if the protocl changes rapidly I'm going to have to
      verify that the versions are compatible.


    - controld:
    
           - CHUNK_WRITTEN partition:path:chunk_id

           - MAP_COMPLETE partition:path:chunk_id

           - REDUCE_COMPLETE reduce_id
                - the given partition has been reduce on the given machine.
           
           - HOST_FAILED

                - indicates that the source machine believes that the given host
                  has failed and is no longer usable.

            - HEARTBEAT

                - heartbeat messages sent from boxes in the wild to report back
                  to the controller.

            - HOST_STATUS

                - sent by a command line app to query the current status of the
                  controller.  Returns a json message to be parsed by the
                  client.
                  
        - Outbound messages
            - MAP partition:path:chunk_id

    - mapd:
        - MAP partition path chunk_id
    
    - dfsd

        - What we could do is a mkchunk command which is higher level and then
          puts most of these actions on the remote end.  Creating the FIRST
          chunk writes the first all the parent directories.

        - You can't remove chunks though.  You can only remove whole files.

        - DELETE

            - ALWAYs recursive.
            - Can delete files or directories.

            - example
            
            DELETE /part/0/pr/tmp/foo HTTP/1.1
            User-Agent: Java
           
            HTTP 200 OK
    
        - PUT /pdfs/part/0/path/to/chunk.dat

            - put a chunk on the remote end
            - makes parent directories if necessary.
        
            - example

            PUT /part/0/pr/tmp/foo/chunk00001.dat HTTP 1.1
            User-Agent: Java
            Content-Type: application/x-peregrine-chunk

            ...

            HTTP 200 OK

            - handles writing to files or output references for additional map jobs
              and giving them to mapd or the reducer.    
              
        - 
          PUT /shuffle/default/from-partition/16/from-chunk/2
          key[],value[]
          
            Used during shuffle to write to a file descriptor.


            
        - GET /pdfs/part/0/path/to/chunk.dat

            - HTTP read on a given chunk file...  Mostly used for speculative
              execution.

        - How do these handle errors?  HTTP 500?
              
    - reduced:
    
        - REDUCE partition path [chunk_id]
            - reduce a parition... starting from the given chunk ID.
        
            
    - we're going to need filesystem commands like stat() which then report back chunk stats.

- when writing the extract how am I going to do the parallel dispatch??? 
    
- Extract jobs should probably be written to disk FIRST (or buffered in memory)
  so that I can compute the checksums.

- Add checksums to chunk files:

    http://www.cryptopp.com/benchmarks.html

    http://en.wikipedia.org/wiki/ZFS

    ZFS supports Fletcher and SHA2:

        http://en.wikipedia.org/wiki/Fletcher%27s_checksum
        http://en.wikipedia.org/wiki/SHA-2


    http://www.strchr.com/hash_functions

    Adler32 vs CRC32 vs Fletcher

    ... 
    

- Make all IO async and have a dedicated reader that reads disk chunks INTO
  memory.  Then I need a consumer which listens to the queue and performs work.
  This way IO is decoupled from CPU and I won't have to wait for disk to do CPU
  work.  This should be about a 10% performance gain.

- I think that all APIs should be cluster aware by default and that the Local
  version writes to the local disk and isn't meant to be used eternally.

  For example:

        PartitionWriter ... writes to all nr_replica machines that host that
        partition.

        LocalPartitionWriter does the writing on each partition on the other
        side of the network.

  For debug and engineering purposes (and testing) using LocalPartitionWriters
  should be easy since this would also make it easy to test.


- If I were to take an ENTIRE chunk, and read it into memory as 1 100MB byte
  array.  Then I could in theory keep a map of the position of a key, and the
  offset into the byte array.

  This way a read of a key would be:

    for( int i = chunk.offsets[0]; i < 8; ++i ) {
    }

  where offsets would contain the position of the key

  This would allow more efficient reading of keys as I could avoid having to do
  an arraycopy for each one.

  I should benchmark this though because the performance boost MIGHT not be
  worth the complexity.

    



- The mapper API should probably be like:


    Controller.map( InputReference() , mapper );
    Controller.reducer( reducer, OutputReference() );


    - At 25 parallel readers I could read at about 80MB/s or so... this means
      40MB/s write throughput to disk (or 40MB/s total input read throughput)
      ... so for 500GB this would mean. 208 minutes or 3.4 hours JUST for the
      reduce phase ... hm.... should I replicate this data to the other machines
      hosting that partition so that I can just quickly resume?  This is a tough
      decision.  I can see why compressing the output of mappers is important so
      that you can make the sort go faster by wrting more data... I have to see
      how CPU bound our reduce phase is going to be.


- Range routing has the advantage that I can keep things globally sorted AND
  group sorted... I just have to emit a different key based on position (or line
  number) in a document if I'm grepping.


- Cluster membership should be defined via gossip protocol in the future but for
  now the controller keeps track of everything.  

    - clusters should get a cluster identifier so that we can bring up multiple
      versions

- Heartbeat protocol should be used to verify that the machines are actually
  there.
   
   


- The architecture should be easy to understand and comprehend.  This means that
  optimizations in the framework can be easily implemented for new and external
  developers.





- On a 1TB disk, how fast do we want it to be available again over gigabit
  ethernet...
    

- step1...

    - benchmark the performance of taking a graph adjacency list / sparse matrix
      in the form of source, targets... and then invert it into target:
      sources... so that I can count the number of sources.

        the first map job should emit:
            (T1, S1)
            (T2, S1)
            (T3, S1)
            (T1, S2)

      And then I should group them like:

        (T1, (S1,S2))
        (T2, (S1))
        (T3, (S1))

      Then the reduce function should return:

        T1, 2
        T2, 1
        T3, 1


- partition setup... start with the number of machines.  The algorithm for
  determining the number of partitions is:

    nr_partitions = nr_hosts


- Using LARGER numbers of partitions means that when a machine fails that I can
1  restore to TWO machines and NOT just one...   TWO machines as the source and
  TWO as the target.  CLEARLY there is a sweet spot.


    - 1000 paritions + 100MB buffer == 100k per chunk written to disk.

    - potentially store all files to disk. how long would it take to read 100k
      at 100MB/s 1ms ... so this is 50% or the original performance... 



        

- One reason that the Pregel API is really cool is that you could implement the
  SAME framework on a single machine instance without a massive amount of wasted
  CPU time due to map reduce.  It COULD even be parallelized somewhat... 
        
- If the config is :

    - partition0: host0, host1, host2
    - partition1: host0, host1, host2

- The route() partition logic should be done via dependency injection so that we
  can make it faster by not having to do an isHashcode comparison for each
  route() usage.  This is a tight loop
    

- how do we store input text so that cat() works efficiently... with a custom
  partition handler.  Make it so tat lines 1-1000 show up on partition 0,
  1001-2000 on parittion 2, etc.
    

- AHHH!!! I put THREE partitions on EACH node... then I can run one reduce on
  EACH for each partition.  Since these boxes replicate these blocks, I can run
  ONE reduce per partition across all three hosts for VERY even CPU
  utilization.  If one of the boxes fails, the controller runs the job on one of
  the backup hosts.
    


- I need to think more about how I want to handle the shuffle stage... I think
  the Mapper should keep a handle on communications channels to shards and that
  ShuffleManager should JUST keep track of chunk job output ... this way if
  they're sorted it can just do a merge joing of the output on disk.

        
        
- we should fallocate chunks , especially chunks that are being written to by
  reducers, so they are on disk contibuous.
        

- I could compute my own minimum spanning tree so that I can route chunks from
  the controller directly and have machines distribute the data FOR me... The
  ideal design will be complicated and involve reading a few more research
  papers on the subject.
  
- compute hashcodes when reading and writing files... then compare the hashcode
  at the end to verify that I have the correct output.

- We have distinct phases that need to be documented: 
      
    - ExtractMap

    - ReduceMap, MergeMap

    - ReduceMerge (when one of the merge inputs comes from the reduce phase)
        - pagerank would require this...

    - ReduceMergeMap ... 


    - ReduceLoad
    - MergeLoad
    - instead of storing the output locally, just load it back into the remote
      storage system.

- The reduce phase should basically be a tiled mere join...

    - each chunk source in the reduce phase is a tile.

    - if the chunk does not have entries that are sorted, first sort each one, 

    - if we do NOT need to

    - the map output might in theory MUCH larger than the map input.
    
        
- Allow the programmer to work with bytes directly for performance reasons.
        
- Make the system so that the Extract phase can actually be the begging of the
  first map/reduce phase. Instead of FIRST writing to the DFS and THEN importing
  the data, if it is already ready to be mapped just read it and stream into the
  map system.

  
        
- The system is modeled after ETL jobs in the form of Extract, Transform, Load:

    http://en.wikipedia.org/wiki/Extract,_transform,_load

    Data is first written into peregrine by using an ExtractWriter and sending
    data to a given path in the system.  Input data is in the form of (K,V) and
    routed to the correct shard based on hash(K).

- The system was designed to be INSANELY small and easy to understand.  The
  original Map Reduce paper makes a great argument that all applications using
  the framework willr realize any performance optimization in the core.

  However, if your core is 100-200k lines of code, this is difficult to
  optimize.
  
- Data should naturally partition without much skew based on the same hash
  function between iterations.

   - Data based on fetching URLs would be a good example.

- Optimized for short running ETL jobs.  Data is designed to be stored within
  exported within peregrine on the local DFS points but isn't meant to be used
  to serve operational reads.  At the end of your map jobs you should export the
  data to your cluster in a system like Cassandra, MySQL, HBase, etc.

- The major optimization is for tasks that join against previously executed map
  reduce jobs.  This optimization is present because we shard the data and store
  the data in a given key on the same machine.  This way it's possible to do a
  map-side join of the data reading from the local host.

 - 
