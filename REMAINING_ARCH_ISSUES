
    - we need a combiner.

    - Fixed number threads

    - ChannelWriter and BufferedChannelWriter so that we can elide writes and send
      them in 16k chunks.

    - compression

    - checksums.

    - No MultiOutputStream but instead ALWAYS use pipeline writes
    
    - documentation:
      - citations (pregel, flume, etc)
      - paper

    - job killing so that the controller can kill off something that is running
      easily .

    - audit ALL the code.

    - ChunkMerger, ChunkSorter, and LocalMerger all use a nearly identical priority
      queue merging system and this will need to be cleaned up to reduce the amount
      of code (and potential bugs)

    - No use of AsyncOutputStream any more... DefaultChunkWriter still uses
      it... It *could* change to AsyncChannelWriter in the future though.

    - Audit everything to make sure we're using zero copy as much as possible.

    - O_NOATIME on files ... ?

    - during intermediate merges we de-serialze the entire record then add the
      new records when in reality we can just append bytes together ... 

    - do a pass to find out what code we can remove.

    - the entire API need to be StructReader and StructWriter based and use
      ChannelBuffers for this backing... 

    - 
