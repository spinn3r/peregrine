
###
#
# The controller which will send and receive RPC messages and handle job
# execution.  This should be the machine you execute your jobs from and the
# controller should be up and online for the full completion of the job.
#

controller=localhost:11111

###
#
# Control port for normal node operations (PFS, job scheduling, etc).
#

port=11112

###
#
# Base directory for all filesystem operations.  The root directory is build
# from the basedir by using the /host/port as a suffix.
#

basedir=/d2/peregrine-fs

###
# 
# Host concurrency in order to determine how many jobs can run on hosts at a
# given time.  

concurrency=2

###
#
# NR replicas to maintain per partition.
# 
# The more hosts you have in your cluster the better as this will allow greater
# parallel recovery.  The maximum parallel recovery can be provided until the
# number of failed hosts is > nr_hosts - nr_replicas at which point we won't be
# able to evenly distribute partitions among new hosts.
#

replicas=1

###
# The size in bytes of the buffer used for receiving shuffle data.  The larger
# the better as this will allow us to put more contiguous data together on disk.

shuffle_buffer_size=10485760

###
# 
# The max number of files we attempt to merge from at a time during the reduce
# phase.

merge_factor=100

###
#
# When > 0 we enable fallocate and allocate files in extents to enable
# contiguous reads and avoid problems with ext3, ext4 (and to some extent XFS)
# writing fragmented files when writing to multiple locations. 

fallocate_extent_size=10485760

###
#
# When true we run posix_fadvise POSIX_FADV_DONTNEED to evict pages from the
# page cache which we no will not be needed again.  This include map chunks
# which have already been mapped and shuffle files that have been reduced.  If
# your job can fit into memory and is iterative with many iterations, it may be
# better to keep this disabled.  The rationale behind fadvising away pages is
# that some Linux kernels get confused with the VFS cache pressure and start
# swapping.  In production environments you may also consider compiling your
# kernel without swap (which is what we do at Spinn3r) which would also fix this
# problem.
#
# For larger jobs that are much greater than memory (2-10x) a better strategy is
# to use all available memory for the combiner and sort buffer.

fadvise_dont_need_enabled=true
